---
title: Orchestrating CloudQuery Syncs with Kestra
description: Learn how to run CloudQuery as a Kestra flow, using the HackerNews API as a source and CSV file as a destination.
tag: tutorial
date: 2024/01/22
---

# Orchestrating CloudQuery Syncs with Kestra

This tutorial shows how to run CloudQuery as a [Kestra](https://kestra.io/) flow, using the HackerNews API as a source and CSV file as a destination. Kestra is an open-source event-driven orchestrator, which has a [dedicated CloudQuery plugin](https://kestra.io/plugins/plugin-cloudquery).

You can use Kestra to: 
- schedule [CloudQuery syncs](https://kestra.io/plugins/tasks/io.kestra.plugin.cloudquery.Sync) in a simple, declarative way using a built-in code editor
- run your syncs based on events from other systems e.g. a new file in your S3 bucket, new message in a queue, or a new webhook request
- monitor your syncs from a friendly UI and get notified when they fail.

## Step 1: Install Kestra

Follow the [Getting started guide](https://kestra.io/docs/getting-started) to launch Kestra locally in Docker. It's as easy as running a single Docker command:

```bash
docker run --pull=always --rm -it -p 8080:8080 --user=root -v /var/run/docker.sock:/var/run/docker.sock -v /tmp:/tmp kestra/kestra:latest-full server local
```

Once the container is running, open http://localhost:8080 in your browser.  


## Step 2: Create a Kestra flow

Inside the Kestra UI, go to the `Flows` page and click on `Create`. You can now paste the following content:

```yaml copy
id: cloudquery_sync
namespace: dev

tasks:
  - id: hn_to_csv
    type: io.kestra.plugin.cloudquery.Sync
    incremental: false
    outputFiles:
      - "cloudquery/**"
    configs:
      - kind: source
        spec:
          name: hackernews
          path: cloudquery/hackernews
          registry: cloudquery
          version: v3.0.21
          tables: ["*"]
          destinations:
            - file
          spec:
            item_concurrency: 100
            start_time: "2024-01-22T00:00:00Z"
      - kind: destination
        spec:
          name: file
          path: cloudquery/file
          version: v3.4.17
          spec:
            path: "cloudquery/{{TABLE}}/{{UUID}}.{{FORMAT}}"
            format: csv
```

The flow will extract all tables from the HackerNews API and load them to a CSV file. You can download that CSV file from the Outputs tab in the Kestra UI after each flow execution. You may notice that the `configs` property is virtually identical to your CloudQuery configuration file. All we had to add was to move the CloudQuery sources and destinations into a list of `configs` in the `cloudquery.Sync` task.

import { Callout } from 'nextra-theme-docs';

<Callout type="info">
Kestra flows are built using a declarative YAML syntax, in the same way as you know it from CloudQuery.
</Callout>

Once you configured the flow in the editor, click on `Save`.

![Kestra Flow Editor Screenshot](/images/docs/deployment/kestra-flow.png)


## Step 3: Run the flow

To manually start a Kestra flow, click on the `Execute` button in the top right corner. Then, confirm by clicking on `Execute`.

You should now see the sync running in the `Executions` tab. You can navigate to the Logs tab to check the logs and validate everything runs as expected. Also, you can download the extracted CSV files from the `Outputs` tab:

![Kestra Flow Execution Screenshot](/images/docs/deployment/kestra-execution.png)

## Step 4: Schedule the flow

To run the flow periodically, we can add a trigger to run it on a schedule. Back in the Flow editor, add the following section:

```yaml copy
triggers:
  - id: schedule
    type: io.kestra.core.models.triggers.types.Schedule
    cron: "0 9 * * *" # every day at 9am
    timezone: US/Eastern
```

This cron expression will run the flow every day at 09:00. You can use [crontab.guru](https://crontab.guru/) to generate cron expressions and replace the one in the example above. Kestra also supports these special values for `cron`:

```text
@yearly
@annually
@monthly
@weekly
@daily
@midnight
@hourly
```

With this in place, remember to click `Save` again. Your CloudQuery sync will now run on a regular schedule.

## Next steps

This tutorial was just a quick introduction to help you get started with a CloudQuery deployment on [Kestra](https://kestra.io/). You can now create additional Kestra tasks to perform transformations, send notifications and more. For more information, check out the [CloudQuery docs](/docs) and the [Kestra docs](https://kestra.io/docs/). 

To productionize your Kestra deployment, you will likely need to deploy it to a cloud environment, such as Kubernetes. For more information, see the [Kestra Deployment with Kubernetes guide](https://kestra.io/docs/installation/kubernetes) and if you have any questions, you can reach the Kestra team [via Community Slack](https://kestra.io/slack).
